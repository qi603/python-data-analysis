{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3.1 Exercise:\n",
    "\n",
    "Add the following data to the `mySerie1` pandas Series object as a new row:\n",
    "\n",
    "```\n",
    "GeneK   25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pandas Series from a dictionary and append it to the `mySerie1` pandas Series object. \n",
    "mySerie2 = pd.Series({\"GeneK\" : 25})\n",
    "mySerie1 = mySerie1.append(mySerie2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively and a bit shorter\n",
    "mySerie1['GeneK'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2.4.1\n",
    "- Select the number of counts in *GeneD* for the second and third experiment. \n",
    "- Add a new column to the dataframe with the average of the three experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subquestion one\n",
    "#df[['counts_exp2','counts_exp3']][3:4]\n",
    "#df.iloc[[3],[1,2]]\n",
    "#df.loc[['GeneD'],['counts_exp2','counts_exp3']]\n",
    "\n",
    "# Subquestion two\n",
    "#df['avg'] = df.sum(axis = 1) / len(df.columns)\n",
    "#df['avg'] = (df['counts_exp1'] + df['counts_exp2'] + df['counts_exp3']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2.4.2\n",
    "\n",
    "- Search in the pandas documentation for the median method and add a column that describes the median countvalues per gene.\n",
    "- Search in the pandas documentation for a method that will count all of the values of one experiment and add it as an extra row to the table. \n",
    "- Remove the row with the sum of the counts that we added in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subquestion one\n",
    "df.median(axis = 1, skipna = True)\n",
    "df[['counts_exp1','counts_exp2','counts_exp3']].median(axis = 1, skipna = True)\n",
    "df['median'] = df[['counts_exp1','counts_exp2','counts_exp3']].median(axis = 1, skipna = True)\n",
    "\n",
    "# Subquestion two \n",
    "df.sum()\n",
    "df[['counts_exp1','counts_exp2','counts_exp3']].sum()\n",
    "df.loc['sum'] = df[['counts_exp1','counts_exp2','counts_exp3','avg']].sum()\n",
    "df\n",
    "\n",
    "# Subquestion three\n",
    "df.drop('sum', axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5.1 Exercise\n",
    "Search for the parameters of `.read_csv` that you need in order to read in the `metagenic.csv` file where:\n",
    "- chromosomes are the index of the rows, and \n",
    "- only the first 10 rows are imported.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metagenic_sub = pd.read_csv('data/metagenic.csv', index_col = 'chr', nrows = 10)\n",
    "metagenic_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5.2 Exercise\n",
    "Can you find a method that will retrieve the indices of all the virginica flowers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[iris['species'] == 'virginica'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5.3 Exercise\n",
    "From the file `metagenic.csv`:\n",
    "1. Sort the table based on the counts in exons in descending way  \n",
    "2. Make a subselection of chromosomes with at least 15 counts in introns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metagenic = pd.read_csv('data/metagenic.csv', index_col = 'chr')\n",
    "#metagenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subquestion one\n",
    "metagenic.sort_values(by=['exon'], ascending = False)\n",
    "\n",
    "# Subquestion two\n",
    "metagenic[metagenic['intron'] >= 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5.4 Exercise\n",
    "In this exercise, derived from the [GTN](https://galaxyproject.github.io/training-material/topics/transcriptomics/tutorials/rna-seq-viz-with-heatmap2/tutorial.html), we will prepare the data to create a heatmap (*Exercise 3.x.y?*) of the top differentially expressed genes in an RNA-seq counts dataset. \n",
    "- [`counts`](https://zenodo.org/record/2529926/files/limma-voom_normalised_counts)\n",
    "- [`de_genes`](https://zenodo.org/record/2529926/files/limma-voom_luminalpregnant-luminallactate)  \n",
    "\n",
    "The latter file contains the results from comparing gene expression in the luminal cells in the pregnant versus lactating mice. It includes genes that are not significantly differentially expressed. Weâ€™ll call genes significantly differentially expressed in this dataset if they pass the thresholds of `adjusted P-value < 0.01` and `fold change of > 1.5 (log2FC of 0.58)`. Filter the top 20 DE genes from that table and create a joint dataframe that contains only the following columns and looks like this:\n",
    "\n",
    "| SYMBOL_x |  MCL1.DG |  MCL1.DH |  MCL1.DI |  MCL1.DJ |   MCL1.DK |   MCL1.DL |  MCL1.LA |  MCL1.LB |  MCL1.LC |  MCL1.LD |  MCL1.LE |  MCL1.LF |\n",
    "|---------:|---------:|---------:|---------:|---------:|----------:|----------:|---------:|---------:|---------:|---------:|---------:|----------|\n",
    "|     Ggt1 | 6.732347 | 6.556047 | 6.558849 | 6.586562 |  6.437596 |  6.394067 | 5.193118 | 5.526432 | 4.223990 | 4.341605 | 7.243899 | 7.354535 |\n",
    "|  Slc39a4 | 2.722153 | 3.027691 | 2.175532 | 1.993214 | -0.193255 | -0.016902 | 3.071502 | 2.928202 | 6.472918 | 6.526836 | 2.430346 | 1.847241 |\n",
    "|      Ppl | 5.102274 | 4.900942 | 5.755087 | 5.951023 |  6.851420 |  6.881858 | 7.359977 | 7.732010 | 8.227118 | 8.437499 | 4.646145 | 4.798986 |\n",
    "| ...   |     ...     |      ...    |   ...       |        ...  |    ...       |         ...  |       ...  |        ...   |      ...    |      ...    |       ...   |       ...   |\n",
    "\n",
    "Save the file as a csv-file in the data-folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "counts = pd.read_csv('https://zenodo.org/record/2529926/files/limma-voom_normalised_counts', sep='\\t')\n",
    "de_genes = pd.read_csv('https://zenodo.org/record/2529926/files/limma-voom_luminalpregnant-luminallactate', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters\n",
    "p_adj_lim = 0.01\n",
    "logFC_lim = 0.58\n",
    "\n",
    "# Filter the non-significantly differentially expressed genes out\n",
    "de_genes = de_genes[abs(de_genes['logFC']) > logFC_lim] \n",
    "de_genes = de_genes[de_genes['P.Value'] < p_adj_lim] \n",
    "\n",
    "# Sort the remaining significantly expressed genes (highest DE genes on top)\n",
    "de_genes = de_genes.sort_values('P.Value')\n",
    "\n",
    "# Filter the top 20 DE genes\n",
    "de_top20 = de_genes.iloc[0:20, :]\n",
    "\n",
    "# Create dataframe for heatmap that is a joined dataframe of the two imported data files\n",
    "df_heatmap = pd.merge(counts, de_top20, on='ENTREZID')\n",
    "\n",
    "# Make a subselection of the columns (genes and DE, see the df above)\n",
    "df_heatmap = df_heatmap.iloc[:, [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]\n",
    "\n",
    "# Set the names of the genes as the row index\n",
    "df_heatmap = df_heatmap.set_index('SYMBOL_x')\n",
    "\n",
    "# Store the dataframe in a csv file for later usage. \n",
    "df_heatmap.to_csv('data/heatmap_data.csv')\n",
    "\n",
    "df_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2.3.1 Exercise:\n",
    "Plot the same barplot but only for Belgium vs the Netherlands. Find a barplot argument that selects which country is selected and hence plotted (instead of making another subselection of the pandas dataframe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2.5.1 Exercise\n",
    "Plot the same graph as given here above with the following modifications:\n",
    "- Use a white background\n",
    "- Color the dots according to its strand orientations\n",
    "- Change x- and y-labels\n",
    "- Remove the upper and right spine of the plots (http://seaborn.pydata.org/generated/seaborn.despine.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line will make a grid on a white background\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Plot the figure\n",
    "ax = sns.scatterplot(x='log2(FC)', y='Log10 P-value', data=volc, hue='Strand')\n",
    "\n",
    "# Change label names\n",
    "plt.xlabel('log2(Fold Change)')\n",
    "plt.ylabel('-log10(P-Value)')\n",
    "\n",
    "# Despine plot\n",
    "sns.despine()\n",
    "\n",
    "#plt.savefig('img/volcanoplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3.1 Exercise \n",
    "Edit the lineplot above with the following adjustments:\n",
    "- Set the style to a white background with ticks on the axes\n",
    "- Set the context to a paper format\n",
    "- Change the figure size\n",
    "- Rename the axes and title of the plot \n",
    "\n",
    "Use the information here below to change the lay-out of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import data\n",
    "\n",
    "# 2. Set style of the plot\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# 3. Define/create the plot\n",
    "plt.figure(figsize=(10,4))\n",
    "ax = sns.lineplot(x = 'Date', y = 'Cost per Mb', data = seqcost)\n",
    "\n",
    "# 4. Tweak lay-out\n",
    "ax.set(xlabel='Years', ylabel='Cost per Mb', title='Cost of sequencing')\n",
    "plt.setp(axs, yticks=[])\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "sns.despine()\n",
    "#plt.savefig('img/seqcost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3.2 Extra exercise\n",
    "Make two subplots underneath each other that plot the Cost per Mb over years and the Total cost. \n",
    "Find more information on subplots [here](https://matplotlib.org/3.1.0/gallery/subplots_axes_and_figures/subplots_demo.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 2, ncols = 1, figsize= (10,7))\n",
    "sns.despine()\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "sns.lineplot(x = 'Date', y = 'Cost per Mb', data = seqcost, color = 'b', ax = axs[0])\n",
    "sns.lineplot(x = 'Date', y = 'Cost per Genome', data = seqcost, color = 'r', ax = axs[1])\n",
    "\n",
    "#plt.setp(axs, yticks=[])\n",
    "plt.setp(axs[0].get_xticklabels(), rotation=90)\n",
    "plt.setp(axs[1].get_xticklabels(), rotation=90)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('img/subplots_seqcost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.2.1 Exercise\n",
    "Calculate the GC-content in the following sequence:\n",
    "```\n",
    "GATTACCACTCACTGACTCACTGACACGAGACCTATACATGATCGCCGGATGATACGAGAATTACTGACGACTAATCCCGGATACTGCATACACTGACGACGACT\n",
    "```\n",
    "- Use the `.count()` method as shown above\n",
    "- Search through Bio.SeqUtils for a function that might help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_seq = Seq(\"GATTACCACTCACTGACTCACTGACACGAGACCTATACATGATCGCCGGATGATACGAGAATTACTGACGACTAATCCCGGATACTGCATACACTGACGACGACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC content\n",
    "100*float(ex_seq.count(\"G\")+ex_seq.count(\"C\"))/len(ex_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in method of Bio.SeqUtils\n",
    "from Bio.SeqUtils import GC\n",
    "GC(ex_seq)\n",
    "\n",
    "# the Bio.SeqUtils.GC() function should automatically cope with mixed case \n",
    "# sequences and the ambiguous nucleotide S which means G or C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- \n",
    "### 5.3.1 Exercise\n",
    "Can you concatenate the following sequences using a for-loop?\n",
    "- Seq(\"ACGT\")\n",
    "- Seq(\"GCTA\")\n",
    "- Seq(\"TACG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "seq1 = Seq(\"ACGT\")\n",
    "seq2 = Seq(\"GCTA\")\n",
    "seq3 = Seq(\"TACG\")\n",
    "list_of_seqs = [seq1, seq2, seq3]\n",
    "\n",
    "concatenated = Seq('')\n",
    "\n",
    "for each_seq in list_of_seqs:\n",
    "    concatenated += each_seq\n",
    "    print(concatenated)\n",
    "    \n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "list_of_seqs = [Seq(\"ACGT\"), Seq(\"GCTA\"),Seq(\"TACG\")]\n",
    "sum(list_of_seqs, Seq(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.7 Exercise\n",
    "\n",
    "Identifying genes is possible by looking for open reading frames (ORFs). For eukaryotic genes we know that there is a complex interaction between promotors, start codons, exons and introns. Nonetheless, for prokaryotic and virus genes this approach would still be useful. \n",
    "\n",
    "Depending on the organism you also need to use the according codon table. In this example we're using a bacterial plasmid fasta file for which we need to use codon [table 11](https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi#SG11). By using the following block of code, we will store the sequence in the variable `record`, define the tranlate tables and define that a possible protein needs to be of a minimum length of 100 AA's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "record = SeqIO.read(\"data/NC_005816.fna\", \"fasta\")\n",
    "table = 11\n",
    "min_pro_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output might look something like this: \n",
    "```\n",
    "GCLMKKSSIVATIITILSGSANAASSQLIP...YRF, - length 315, strand 1, frame 0\n",
    "KSGELRQTPPASSTLHLRLILQRSGVMMEL...NPE, - length 285, strand 1, frame 1\n",
    "NQIQGVICSPDSGEFMVTFETVMEIKILHK...GVA, - length 355, strand 1, frame 2\n",
    "QGSGYAFPHASILSGIAMSHFYFLVLHAVK...CSD, - length 114, strand -1, frame 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a for loop to access first the + strand and then the - strand\n",
    "for strand, nuc in [(+1, record.seq), (-1, record.seq.reverse_complement())]:\n",
    "    \n",
    "    # Allow frame shifts \n",
    "    for frame in range(3):\n",
    "        \n",
    "        # Length of sequence adjusted for frame shift \n",
    "        length = 3 * ((len(record)-frame)  // 3)\n",
    "        \n",
    "        # Translate sequence (nuc) to AA's. Split at * which decodes for a stop codon. These are all the ORFs\n",
    "        for pro in nuc[frame:frame+length].translate(table).split(\"*\"):\n",
    "            \n",
    "            # if length of ORF is >= predefined length\n",
    "            if len(pro) >= min_pro_len:\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"{pro[:30]}...{pro[-3:]}, - length {len(pro)}, strand {strand}, frame {frame}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, function-wise. Define the arguments and function\n",
    "def extract_ORF(record, strand, frame, table, min_len):\n",
    "    \"\"\"extract_ORF accepts a sequence record object as argument together with a strand orientation \n",
    "    and frameshift and will give you as an output all of the possible ORFs from that sequence record object\n",
    "    that are longer than a predefined minimal length of AAs using a specific codon table\"\"\"\n",
    "    \n",
    "    # Create empty dataframe that will store all the information\n",
    "    seq_info = pd.DataFrame(columns=[\"Sequence\", \"Length\", \"Strand\", \"Frame\"])\n",
    "\n",
    "    if strand == -1:\n",
    "        print(\"Antisense strand orientation\")\n",
    "        record_seq = record.seq.reverse_complement()\n",
    "    elif strand == +1:\n",
    "        print(\"Sense strand orientation\")\n",
    "        record_seq = record.seq\n",
    "    else:\n",
    "        print(\"No correct strand information\")\n",
    "    \n",
    "    length = 3 * ((len(record)-frame)  // 3)  \n",
    "    if frame == 0:\n",
    "        print(\"No frameshift\")\n",
    "    elif frame == 1:\n",
    "        print(\"Frameshift 1\")\n",
    "        record_seq =  record_seq[frame:frame+length]\n",
    "    elif frame == 2: \n",
    "        record_seq =  record_seq[frame:frame+length]\n",
    "        print(\"Frameshift 2\")\n",
    "\n",
    "    for sub_prot in record_seq.translate(table=table).split('*'):\n",
    "        if len(sub_prot) >= min_len:\n",
    "            seq_info = seq_info.append({'Sequence': str(sub_prot), \n",
    "                                        'Length': len(sub_prot),\n",
    "                                        'Strand': strand,\n",
    "                                        'Frame': frame}, ignore_index = True)\n",
    "    return seq_info\n",
    "\n",
    "extract_ORF(record=record, strand=+1, frame=2, table=11, min_len=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1.1 Exercise\n",
    "Find the title of all the articles related to the genbank entry 'NC_005816'. Import this file using the following block of code.  \n",
    "\n",
    "Extra: Create a list of URL-links that brings you directly to the article. For this you can use the Pubmed ID in combination with `https://pubmed.ncbi.nlm.nih.gov/`. \n",
    "\n",
    "\n",
    "Hint: look at the section of *references* of [this link](https://biopython.readthedocs.io/en/latest/chapter_seq_annot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "record = SeqIO.read(\"data/NC_005816.gb\",\"gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create an empty list that will store the URL-links. \n",
    "list_pubmed = []\n",
    "base_url = 'https://pubmed.ncbi.nlm.nih.gov/'\n",
    "for ref in record.annotations['references']:\n",
    "    # The titles of the journals are written in the title submodule\n",
    "    print(ref.title)\n",
    "    \n",
    "    # Extra: if there is a pubmed ID\n",
    "    if not ref.pubmed_id:\n",
    "        # Prepare to add pubmed ID together with Base URL\n",
    "        url_link = (base_url, ref.pubmed_id)\n",
    "        # Join the pubmed ID with Base URL and append this to the list of Pubmed ID's\n",
    "        list_pubmed.append(''.join(url_link))\n",
    "print(list_pubmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 7.1.1 Exercise\n",
    "Make a list that contains the organism of each record in the `data/ls_orchid.gbk`-file. \n",
    "\n",
    "Tip: you should make an empty list, iterate over all the records, access the organism and append it to the  list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 by using the annotations (cleaner)\n",
    "all_species= []\n",
    "for seq_record in SeqIO.parse(\"data/ls_orchid.gbk\",\"genbank\"):\n",
    "    all_species.append(seq_record.annotations[\"organism\"])\n",
    "    \n",
    "print(set(all_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 by using the description (can be a bit tricky if the name of the organism is not on the second location)\n",
    "all_species = []\n",
    "for seq_record in SeqIO.parse(\"data/ls_orchid.fasta\",\"fasta\"):\n",
    "    all_species.append(seq_record.description.split()[1])\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Exercise\n",
    "Write a script that blasts the top 5 overrepresented sequences in a fastq-file. Save the following information in a pandas dataframe: title, e-value and score. \n",
    "\n",
    "\n",
    "Here is a table that is part of the output of a FastQC process. The raw data can be obtained from the zipped folder that is always created as part of the process. This part represents the overrepresented sequences in a fastq file. The file that contains the data is stored under `data/overrepresented_sequences.txt`. \n",
    "\n",
    "\n",
    "```\n",
    "#Sequence\tCount\tPercentage\tPossible Source\n",
    "GCGCCAGGTTCCACACGAACGTGCGTTCAACGTGACGGGCGAGAGGGCGG\t634749\t0.9399698125201895\tNo Hit\n",
    "GCCAGGTTCCACACGAACGTGCGTTCAACGTGACGGGCGAGAGGGCGGCC\t437871\t0.6484224816077345\tNo Hit\n",
    "GGGGACAGTCCGCCCCGCCCCCCACCGGGCCCCGAGAGAGGCGACGGAGG\t319343\t0.47289996493044484\tNo Hit\n",
    "GGCTTCCTCGGCCCCGGGATTCGGCGAAAGCTGCGGCCGGAGGGCTGTAA\t310651\t0.4600283926862577\tNo Hit\n",
    "GGGCCTTCCCGGCCGTCCCGGAGCCGGTCGCGGCGCACCGCCACGGTGGA\t260086\t0.3851490725611636\tNo Hit\n",
    "ACGAATGGTTTAGCGCCAGGTTCCACACGAACGTGCGTTCAACGTGACGG\t247602\t0.3666621066273818\tNo Hit\n",
    "CGGCTTCGTCGGGAGACGCGTGACCGACGGTCCCCCCGGGACCCGACGGC\t170383\t0.25231213687083787   No Hit\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example output: \n",
    "\n",
    "| / | Title |                                             Score | E-value |                \n",
    "|------:|--------------------------------------------------:|--------:|-------------:|\n",
    "    |     0 | Staphylococcus aureus...                      |    100.0 | 1.510770e-15 |  \n",
    "|     1 | ... |    ... | ... |   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of overrepresented sequences it should blast (exercise = 5 but that takes a while)\n",
    "nr = 2\n",
    "\n",
    "# The output of the fastQC process has already been filtered a bit\n",
    "df_overrepr = pd.read_table('data/overrepresented_sequences.txt', sep='\\t') \n",
    "# Create df that will contain results\n",
    "df_results = pd.DataFrame(columns=['Title','Score','E-value'])\n",
    "\n",
    "\n",
    "\n",
    "# Only select 5 most overrepresented sequences\n",
    "for i in range(nr-1):\n",
    "    # Extract sequence\n",
    "    seq = df_overrepr['#Sequence'][i]\n",
    "    print(f'Sequence: {seq}, at index: {i}')\n",
    "    # Make Seq for Biopython\n",
    "    seq_blast = Seq(seq)\n",
    "    # blast sequence\n",
    "    print(\"Blasting\")\n",
    "    result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", seq_blast)\n",
    "\n",
    "    # Parse the blast handle and extract only first record (without writing it to a file first)\n",
    "    blast_record = NCBIXML.read(result_handle)\n",
    "    \n",
    "    # Each record has \n",
    "    descr = blast_record.descriptions[0]\n",
    "    title = descr.title\n",
    "    score = descr.score\n",
    "    e = descr.e\n",
    "    df_results = df_results.append({'Title': title, \n",
    "                   'Score': score,\n",
    "                   'E-value': e}, ignore_index=True)\n",
    "    print(df_results)\n",
    "        \n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Two more exercises\n",
    "The following two exercises are a bit longer and require a combination of the materials that we learned today (9.1) or dive into the world of proteins (9.2). The choice is yours as to which one might be more relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Diagnosing Sickle Cell Anemia\n",
    "[This link](https://krother.gitbooks.io/biopython-tutorial/content/sicklecell.html) will bring you to a great example exercise from Kristian Rother that combines all of the things that we learned today. \n",
    "\n",
    "Your goal is to develop an experimental test that reveals whether a patient suffers from the hereditary disease sickle cell anemia. The test for diagnosis should use a restriction enzyme on a patientsâ€™ DNA sample. For the test to work, you need to know exactly what genetic difference to test against. In this tutorial, you will use Biopython to find out.\n",
    "\n",
    "The idea is to compare DNA and protein sequences of sickle cell and healthy globin, and to try out different restriction enzymes on them.\n",
    "\n",
    "This tutorial consists of four parts:\n",
    "\n",
    "1. Use the module Bio.Entrez to retrieve DNA and protein sequences from NCBI databases.\n",
    "2. Use the module Bio.SeqIO to read, write, and filter information in sequence files.\n",
    "3. Use the modules Bio.Seq and Bio.SeqRecord to extract exons, transcribe and translate them to protein sequences.\n",
    "4. Use the module re to identify restriction sites. Regular expressions are not part of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check solutions with/at tuur.muyldermans@vib.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Protein plots\n",
    "Make two 3D plots of protein structures using the matplotlib pyplot library. For this you can use a Biopython module to retrieve the protein's PDB data and another one to parse it. \n",
    "1. The first one of the [human oxyhaemoglobin](https://www.rcsb.org/structure/1hho) chain A.\n",
    "2. The second one with the superposition of chain B on top of chain A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1\n",
    "from Bio.PDB import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pdbl = PDBList()\n",
    "pdbl.retrieve_pdb_file(\"1HHO\")\n",
    "\n",
    "parser = MMCIFParser()\n",
    "struct = parser.get_structure(\"1HHO\", \"hh/1hho.cif\")\n",
    "\n",
    "# Part 1: Plot a structure\n",
    "calphas = [res[\"CA\"].get_coord() for res in struct[0][\"A\"] if \"CA\" in res]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot([xyz[0] for xyz in calphas],\n",
    "        [xyz[1] for xyz in calphas],\n",
    "        [xyz[2] for xyz in calphas], color='skyblue')\n",
    "ax.view_init(30, 185)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Plot an aligned pair of structures\n",
    "chain_A = [res[\"CA\"] for res in struct[0][\"A\"] if \"CA\" in res]\n",
    "chain_B = [res[\"CA\"] for res in struct[0][\"B\"] if \"CA\" in res][:141] # Explain superposition\n",
    "\n",
    "sup = Superimposer()\n",
    "sup.set_atoms(chain_A, chain_B)\n",
    "sup.apply(chain_B)\n",
    "\n",
    "calphas_A = [atom.get_coord() for atom in chain_A]\n",
    "calphas_B = [atom.get_coord() for atom in chain_B]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot([xyz[0] for xyz in calphas_A],\n",
    "        [xyz[1] for xyz in calphas_A],\n",
    "        [xyz[2] for xyz in calphas_A], color='green')\n",
    "ax.plot([xyz[0] for xyz in calphas_B],\n",
    "        [xyz[1] for xyz in calphas_B],\n",
    "        [xyz[2] for xyz in calphas_B], color='red')\n",
    "ax.view_init(30, 185)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
